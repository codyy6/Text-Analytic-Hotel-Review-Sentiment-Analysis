{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "df = pd.read_csv('7282_1.csv')\n",
    "## Rename columns \n",
    "df.rename(columns = {'reviews.rating':'ratings', 'reviews.text':'reviews','reviews.username':'username'}, inplace = True)\n",
    "\n",
    "## drop null values\n",
    "df.dropna(subset=['ratings'], inplace=True)\n",
    "df.dropna(subset=['reviews'], inplace=True)\n",
    "\n",
    "## drop duplicates\n",
    "df.drop_duplicates(subset=['username'])\n",
    "df.dropna(subset=['ratings'], inplace=True)\n",
    "\n",
    "## drop row 98 that has an invalid review \"xxxxxxxxxxxxxxx\"\n",
    "df.drop(98, inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "## standardize the ratings\n",
    "filtered_values = df.loc[df['ratings'] > 5, 'ratings']\n",
    "# Divide the filtered values by 2\n",
    "filtered_values_divided = filtered_values / 2\n",
    "# Update the original DataFrame with the new values\n",
    "df.loc[df['ratings'] > 5, 'ratings'] = filtered_values_divided\n",
    "\n",
    "\n",
    "## categorizing ratings\n",
    "df.loc[(df['ratings'] >= 4.5), 'ratings'] = 5.0\n",
    "\n",
    "df.loc[(df['ratings'] >= 3.5) & (df['ratings'] < 4.5), 'ratings'] = 4.0\n",
    "\n",
    "df.loc[(df['ratings'] >= 2.5) & (df['ratings'] < 3.5), 'ratings'] = 3.0\n",
    "\n",
    "df.loc[(df['ratings'] >= 1.5) & (df['ratings'] < 2.5), 'ratings'] = 2.0\n",
    "\n",
    "df.loc[(df['ratings'] >= 0.5) & (df['ratings'] < 1.5), 'ratings'] = 1.0\n",
    "\n",
    "df.loc[(df['ratings'] < 0.5), 'ratings'] = 0.0\n",
    "\n",
    "## sentiment mask based on ratings \n",
    "df['sentiment'] = df['ratings'].map({0:'negative', 1:'negative', 2:'negative', 3:'neutral', 4:'positive', 5:'positive'})\n",
    "df = df[['reviews', 'sentiment']]\n",
    "\n",
    "## drop all rows where sentiment is neutral\n",
    "df.drop(df[df['sentiment'] =='neutral'].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aymanadil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/aymanadil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aymanadil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def remove_Stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "#change word back to its original form\n",
    "def lemmatize_text(text):\n",
    "    wordlist = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        wordlist.append(\" \".join(words))\n",
    "    return \" \".join(wordlist)\n",
    "\n",
    "#remove special characters and punctuations from the text\n",
    "def clean_text(text):\n",
    "    delete_dic = {sp_character: \"\" for sp_character in string.punctuation}\n",
    "    delete_dic[\" \"] = \" \"\n",
    "    table = str.maketrans(delete_dic)\n",
    "    text1 = text.translate(table)\n",
    "    textArr = text1.split()\n",
    "    text2 = \" \".join([word for word in textArr])\n",
    "    return text2.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hotellihuone oli ullakolla jossa ei pystynyt k...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dont stay unless youre le 2 foot tall like sle...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>wall extremely thin hear everything excessive ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>share opinion businesswith yp visitor across u...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>share opinion businesswith yp visitor across u...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>share opinion businesswith yp visitor across u...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>share opinion businesswith yp visitor across u...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>pathetic discriminatory free shuttle service a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>room clean hotel worker good breakfast also go...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>visited comfort suite new iberia louisiana dau...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviews sentiment\n",
       "19  hotellihuone oli ullakolla jossa ei pystynyt k...  negative\n",
       "20  dont stay unless youre le 2 foot tall like sle...  negative\n",
       "44  wall extremely thin hear everything excessive ...  negative\n",
       "57  share opinion businesswith yp visitor across u...  negative\n",
       "58  share opinion businesswith yp visitor across u...  negative\n",
       "59  share opinion businesswith yp visitor across u...  negative\n",
       "79  share opinion businesswith yp visitor across u...  negative\n",
       "82  pathetic discriminatory free shuttle service a...  negative\n",
       "85  room clean hotel worker good breakfast also go...  negative\n",
       "91  visited comfort suite new iberia louisiana dau...  negative"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews'] = df['reviews'].apply(clean_text)\n",
    "df['reviews'] = df['reviews'].apply(remove_Stopwords)\n",
    "df['reviews'] = df['reviews'].apply(lemmatize_text)\n",
    "\n",
    "# negative_df = df[df['sentiment'] == 'negative']\n",
    "# negative_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29243, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(df[df['sentiment'] == 'neutral'].index, inplace=True)\n",
    "\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
